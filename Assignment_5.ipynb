{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bbf6b54",
   "metadata": {},
   "source": [
    "# Assignment_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b748c3",
   "metadata": {},
   "source": [
    "## 1. What are the key tasks that machine learning entails? What does data pre-processing imply?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a336be0",
   "metadata": {},
   "source": [
    "Ans:- Regression, Classification, Clustering, Transcription, Machine translation, Anomaly detection, Synthesis & sampling, \n",
    "Estimation of probability density and probability mass function. - These tasks that machine learning do.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3964c5",
   "metadata": {},
   "source": [
    "Data pre-processing imply that changing the raw data into a clean data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50185745",
   "metadata": {},
   "source": [
    "## 2. Describe quantitative and qualitative data in depth. Make a distinction between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed40f90",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "1. Quantitative data- Quantitative data is the process of collecting and analyzing numerical data. It can be used to find patterns and averages, make predictions, test causal relationships, and generalize results to wider populations.\n",
    "2. Qualitative data- Qualitative research involves collecting and analyzing non-numerical data (e.g., text, video, or audio) to understand concepts, opinions, or experiences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dfa53e",
   "metadata": {},
   "source": [
    "Distinction between the two\n",
    "1. Qualitative data is the data type that consists of descriptive statements. On the other hand, quantitative data is the data type that can be measured and expressed numerically.\n",
    "2. Qualitative data is text-based while quantitative data is number based.\n",
    "3. Statistical analysis is easier with quantitative data than qualitative data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8cd6a",
   "metadata": {},
   "source": [
    "## 3. Create a basic data collection that includes some sample records. Have at least one attribute from each of the machine learning data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabacd9f",
   "metadata": {},
   "source": [
    "Ans:-Data collection is a systematic process of gathering observations or measurements. Whether you are performing research for business, governmental or academic purposes, data collection allows you to gain first-hand knowledge and original insights into our research problem. Before you begin collecting data, you need to consider:\n",
    "The aim of the research\n",
    "The type of data that you will collect\n",
    "The methods and procedures you will use to collect, store, and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02935cc",
   "metadata": {},
   "source": [
    "## 4. What are the various causes of machine learning data issues? What are the ramifications?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877739d",
   "metadata": {},
   "source": [
    "Ans:-The various causes of machine learning data issues are- 1.InsufficientTraining Data, 2.Poor quality of data, 3. Non-representative training data, 4. Overfitting and Underfitting 4. Data Bias, 5.Lack of Explainability 6.Slow implementations and results etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497038d",
   "metadata": {},
   "source": [
    "Model will not perform well, unclean data lead to less accuracy in classification and low-quality results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad05640",
   "metadata": {},
   "source": [
    "## 5. Demonstrate various approaches to categorical data exploration with appropriate examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a369ec",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "1. Unique value count - One of the first things which can be useful during data exploration is to see how many unique values are there in categorical columns. This gives an idea of what is the data about. \n",
    "2. Frequency Count - Frequency count is finding how frequent individual values occur in column. \n",
    "3. Variance- When it comes to analysing numeric values, some basic information such as minimum, maximum and variance are very useful. Variance gives a good indication how the values are spread.\n",
    "4. Pareto Analysis- Pareto analysis is a creative way of focusing on what is important. Pareto 80–20 rule can be effectively used in data exploration.\n",
    "5. Histogram-  Histogram gives information on the range of values in which most of the values fall. It also gives information on whether there is any skew in data.\n",
    "6. Correlation Heat-map between all numeric columns- The term correlation refers to a mutual relationship or association between two things. It gives an idea on how the columns are related to each other\n",
    "7. Pearson Correlation and Trend between two numeric columns- Once you have visualised correlation heat-map , the next step is to see the correlation trend between two specific numeric columns. \n",
    "8. Clustering or Segmentation- Once you have determined the number of clusters, the next step is to divide all data into specific number of clusters or segments.\n",
    "9. Outlier analysis for multiple columns- One of the important step of exploratory data analysis is finding outlier based on multiple column (at row level). This can be obtained using various algorithms such as Isolation forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca9f72",
   "metadata": {},
   "source": [
    "## 6. How would the learning activity be affected if certain variables have missing values? Having said that, what can be done about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddea723",
   "metadata": {},
   "source": [
    "Ans:-Many machine learning algorithms fail if the dataset contains missing values. However, algorithms like K-nearest and Naive Bayes support data with missing values.\n",
    "We may end up building a biased machine learning model, leading to incorrect results if the missing values are not handled properly.\n",
    "Missing data can lead to a lack of precision in the statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119269bb",
   "metadata": {},
   "source": [
    "## 7. Describe the various methods for dealing with missing data values in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5269e914",
   "metadata": {},
   "source": [
    "Ans:-When dealing with missing data, data scientists can use two primary methods to solve the error- 1.imputation or 2.the removal of data.The imputation method develops reasonable guesses for missing data. It’s most useful when the percentage of missing data is low. If the portion of missing data is too high, the results lack natural variation that could result in an effective model.When dealing with data that is missing at random, related data can be deleted to reduce bias. Removing data may not be the best option if there are not enough observations to result in a reliable analysis. In some situations, observation of specific events or factors may be required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8ccff",
   "metadata": {},
   "source": [
    "Instead of deletion, data scientists have multiple solutions to impute the value of missing data. Depending why the data are missing, imputation methods can deliver reasonably reliable results.we can replacing missing data by imputation methods.\n",
    "1. Mean, Median and Mode imputation, but This method does not use time-series characteristics or depend on the relationship between the variables.\n",
    "2. Another option is to use time-series specific methods when appropriate to impute data. \n",
    "3. Last Observation Carried Forward (LOCF) & Next Observation Carried Backward (NOCB).These options are used to analyze longitudinal repeated measures data. In this method, every missing value is replaced with the last observed value. However, this method may introduce bias.\n",
    "4. Linear Interpolation -Linear interpolation is often used to approximate a value of some function by using two known values of that function at other points. This formula can also be understood as a weighted average. The weights are inversely related to the distance from the end points to the unknown point. The closer point has more influence than the farther point. \n",
    "5. Multiple Imputation and 6.K Nearest Neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feac6637",
   "metadata": {},
   "source": [
    "## 8. What are the various data pre-processing techniques? Explain dimensionality reduction and function selection in a few words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63826f05",
   "metadata": {},
   "source": [
    "Ans:-The various data pre-processing techniques are Data Cleaning,Dimensionality Reduction, Feature Engineering, Sampling Data, DataTransformation, Imbalanced Data. \n",
    "1. Dimensionality reduction and function selection- \n",
    "The dimensionality reduction is concerned with reducing the number of input features in training data.Feature selection refers to the process of selecting the most important variables (features) related to our prediction variable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67300305",
   "metadata": {},
   "source": [
    "## 9.\n",
    "\n",
    "i. What is the IQR? What criteria are used to assess it?\n",
    "\n",
    "ii. Describe the various components of a box plot in detail? When will the lower whisker surpass the upper whisker in length? How can box plots be used to identify outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd7c62",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "### i. What is the IQR? What criteria are used to assess it?\n",
    "The interquartile range rule is useful in detecting the presence of outliers. Any set of data can be described by its five-number summary. These five numbers, which give you the information you need to find patterns and outliers, consist of (in ascending order):\n",
    "The minimum or lowest value of the dataset\n",
    "The first quartile Q1, which represents a quarter of the way through the list of all data\n",
    "The median of the data set, which represents the midpoint of the whole list of data\n",
    "The third quartile Q3, which represents three-quarters of the way through the list of all data\n",
    "The maximum or highest value of the data set.All you do to find it is subtract the first quartile from the third quartile:\n",
    "\n",
    "IQR = Q3 – Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c68df",
   "metadata": {},
   "source": [
    "A box and whisker plot—also called a box plot—displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee0877",
   "metadata": {},
   "source": [
    "Box plots are useful as they show outliers within a data set\n",
    "An outlier is an observation that is numerically distant from the rest of the data.\n",
    "When reviewing a box plot, an outlier is defined as a data point that is located outside the whiskers of the box plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84daf0e",
   "metadata": {},
   "source": [
    "## 10. Make brief notes on any two of the following:\n",
    "\n",
    "1. Data collected at regular intervals\n",
    "\n",
    "2. The gap between the quartiles\n",
    "\n",
    "3. Use a cross-tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836692b6",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "1. The gap between the quartiles - The IQR describes the middle 50% of values when ordered from lowest to highest. To find the interquartile range (IQR), ​first find the median (middle value) of the lower and upper half of the data. These values are quartile 1 (Q1) and quartile 3 (Q3). The IQR is the difference between Q3 and Q1.\n",
    "2. Use a cross-tab - Cross tabulation (crosstab) is a useful analysis tool commonly used to compare the results for one or more variables with the results of another variable. It is used with data on a nominal scale, where variables are named or labeled with no specific order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322167d",
   "metadata": {},
   "source": [
    "## 1. Make a comparison between:\n",
    "\n",
    "1. Data with nominal and ordinal values\n",
    "\n",
    "2. Histogram and box plot\n",
    "\n",
    "3. The average and median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e566da5",
   "metadata": {},
   "source": [
    "Ans:-\n",
    "1. Data with nominal and ordinal values- Nominal data is classified without a natural order or rank, whereas ordinal data has a predetermined or natural order. On the other hand, numerical or quantitative data will always be a number that can be measured.\n",
    "2. Histogram and box plot- Histograms are a special kind of bar graph that shows a bar for a range of data values instead of a single value. A box plot is a data display that draws a box over a number line to show the interquartile range of the data. The 'whiskers' of a box plot show the least and greatest values in the data set.\n",
    "3. The average and median- The average is calculated by adding up all of the individual values and dividing this total by the number of observations. The median is calculated by taking the “middle” value, the value for which half of the observations are larger and half are smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a76f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
